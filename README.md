# SkySentryAI
At SkySentryAI, our mission is to revolutionize transportation management and safety during inclement weather. We are dedicated to empowering Department of Transportation agencies with advanced AI technology to make informed, proactive decisions. Our goal is to enhance road safety, reduce accidents, and minimize traffic disruptions during adverse weather conditions. By providing real-time weather insights and predictive analysis, we enable DOTs to determine staffing needs, deploy resources strategically, and mitigate weather-related incidents effectively. We are committed to creating a safer, more efficient, and resilient transportation network for the benefit of all communities we serve.
## Logo

## Problem
Weather forecasts are not always accurate. Day in and day out there is unexpected poor weather around the world. The problem is that while there may be good weather in a town, there may be one section of a town that doesn't. We want to help Department of Transportation agencies know where and how many people to staff for a certain day. Furthermore, we want to help them redirect their staff to areas that would need the assistance more. For example an area that is foggy or rainy tends to need more assistance than where it is clear and sunny.

##  Data Deck
[Google Slide Data Deck](https://docs.google.com/presentation/d/1JuHDfsJL5S2unNAP_6iWqWC_wB_WmdSKYS6D0M1KvJ8/edit?usp=sharing)

## Image Filters

## AlexNet

AlexNet is a convolutional neural network (CNN) architecture that played a pivotal role in the advancement of deep learning and computer vision. Developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, it achieved significant success by winning the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012, marking a breakthrough in image classification tasks.

**Key Features:**

1. **Deep Architecture:** AlexNet comprises eight layers, including five convolutional layers and three fully connected layers. It introduced a deep neural network architecture, challenging the conventional belief that deep networks were difficult to train.

2. **Rectified Linear Unit (ReLU):** Extensive use of the rectified linear unit activation function (ReLU) in hidden layers to mitigate the vanishing gradient problem and accelerate training convergence.

3. **Local Response Normalization (LRN):** Implementation of local response normalization in convolutional layers to enhance the network's ability to generalize and respond to variations in input data.

4. **Dropout:** Use of dropout to prevent overfitting by randomly deactivating a percentage of neurons, reducing co-dependency among neurons and improving generalization.

5. **Data Augmentation:** Incorporation of data augmentation techniques during training, such as cropping and flipping, to increase the diversity of the training dataset and improve the model's robustness.

6. **GPU Acceleration:** One of the first neural networks designed to take advantage of Graphics Processing Units (GPUs), significantly accelerating the training process and making deep learning more feasible for large-scale datasets.

AlexNet's success marked the beginning of a new era in deep learning, inspiring the development of subsequent, more complex neural network architectures. Its principles continue to influence the design of modern convolutional neural networks used in various applications, including image recognition, object detection, and image segmentation.

---
